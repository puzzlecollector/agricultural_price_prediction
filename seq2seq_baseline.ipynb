{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from tqdm import tqdm\n",
    "import random \n",
    "import os \n",
    "import torch \n",
    "from torch import nn \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>요일</th>\n",
       "      <th>배추_거래량(kg)</th>\n",
       "      <th>배추_가격(원/kg)</th>\n",
       "      <th>무_거래량(kg)</th>\n",
       "      <th>무_가격(원/kg)</th>\n",
       "      <th>양파_거래량(kg)</th>\n",
       "      <th>양파_가격(원/kg)</th>\n",
       "      <th>건고추_거래량(kg)</th>\n",
       "      <th>건고추_가격(원/kg)</th>\n",
       "      <th>...</th>\n",
       "      <th>청상추_거래량(kg)</th>\n",
       "      <th>청상추_가격(원/kg)</th>\n",
       "      <th>백다다기_거래량(kg)</th>\n",
       "      <th>백다다기_가격(원/kg)</th>\n",
       "      <th>애호박_거래량(kg)</th>\n",
       "      <th>애호박_가격(원/kg)</th>\n",
       "      <th>캠벨얼리_거래량(kg)</th>\n",
       "      <th>캠벨얼리_가격(원/kg)</th>\n",
       "      <th>샤인마스캇_거래량(kg)</th>\n",
       "      <th>샤인마스캇_가격(원/kg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>금요일</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>토요일</td>\n",
       "      <td>80860.0</td>\n",
       "      <td>329.0</td>\n",
       "      <td>80272.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>122787.5</td>\n",
       "      <td>1281.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5125.0</td>\n",
       "      <td>9235.0</td>\n",
       "      <td>434.0</td>\n",
       "      <td>2109.0</td>\n",
       "      <td>19159.0</td>\n",
       "      <td>2414.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-03</td>\n",
       "      <td>일요일</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>월요일</td>\n",
       "      <td>1422742.5</td>\n",
       "      <td>478.0</td>\n",
       "      <td>1699653.7</td>\n",
       "      <td>382.0</td>\n",
       "      <td>2315079.0</td>\n",
       "      <td>1235.0</td>\n",
       "      <td>699.0</td>\n",
       "      <td>4464.0</td>\n",
       "      <td>...</td>\n",
       "      <td>38525.5</td>\n",
       "      <td>7631.0</td>\n",
       "      <td>500702.0</td>\n",
       "      <td>2046.0</td>\n",
       "      <td>620539.0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>2703.8</td>\n",
       "      <td>3885.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-05</td>\n",
       "      <td>화요일</td>\n",
       "      <td>1167241.0</td>\n",
       "      <td>442.0</td>\n",
       "      <td>1423482.3</td>\n",
       "      <td>422.0</td>\n",
       "      <td>2092960.1</td>\n",
       "      <td>1213.0</td>\n",
       "      <td>1112.6</td>\n",
       "      <td>4342.0</td>\n",
       "      <td>...</td>\n",
       "      <td>32615.0</td>\n",
       "      <td>6926.0</td>\n",
       "      <td>147638.0</td>\n",
       "      <td>2268.0</td>\n",
       "      <td>231958.0</td>\n",
       "      <td>2178.0</td>\n",
       "      <td>8810.0</td>\n",
       "      <td>2853.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date   요일  배추_거래량(kg)  배추_가격(원/kg)  무_거래량(kg)  무_가격(원/kg)  \\\n",
       "0  2016-01-01  금요일         0.0          0.0        0.0         0.0   \n",
       "1  2016-01-02  토요일     80860.0        329.0    80272.0       360.0   \n",
       "2  2016-01-03  일요일         0.0          0.0        0.0         0.0   \n",
       "3  2016-01-04  월요일   1422742.5        478.0  1699653.7       382.0   \n",
       "4  2016-01-05  화요일   1167241.0        442.0  1423482.3       422.0   \n",
       "\n",
       "   양파_거래량(kg)  양파_가격(원/kg)  건고추_거래량(kg)  건고추_가격(원/kg)  ...  청상추_거래량(kg)  \\\n",
       "0         0.0          0.0          0.0           0.0  ...          0.0   \n",
       "1    122787.5       1281.0          3.0       11000.0  ...       5125.0   \n",
       "2         0.0          0.0          0.0           0.0  ...          0.0   \n",
       "3   2315079.0       1235.0        699.0        4464.0  ...      38525.5   \n",
       "4   2092960.1       1213.0       1112.6        4342.0  ...      32615.0   \n",
       "\n",
       "   청상추_가격(원/kg)  백다다기_거래량(kg)  백다다기_가격(원/kg)  애호박_거래량(kg)  애호박_가격(원/kg)  \\\n",
       "0           0.0           0.0            0.0          0.0           0.0   \n",
       "1        9235.0         434.0         2109.0      19159.0        2414.0   \n",
       "2           0.0           0.0            0.0          0.0           0.0   \n",
       "3        7631.0      500702.0         2046.0     620539.0        2018.0   \n",
       "4        6926.0      147638.0         2268.0     231958.0        2178.0   \n",
       "\n",
       "   캠벨얼리_거래량(kg)  캠벨얼리_가격(원/kg)  샤인마스캇_거래량(kg)  샤인마스캇_가격(원/kg)  \n",
       "0           0.0            0.0            0.0             0.0  \n",
       "1         880.0         2014.0            0.0             0.0  \n",
       "2           0.0            0.0            0.0             0.0  \n",
       "3        2703.8         3885.0            0.0             0.0  \n",
       "4        8810.0         2853.0            0.0             0.0  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"public_data/train.csv\") \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "week_day_map = {} \n",
    "for i,d in enumerate(data['요일'].unique()):\n",
    "    week_day_map[d] = i \n",
    "    \n",
    "data['요일'] = data['요일'].map(week_day_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = data.iloc[:,1:].max(0) \n",
    "data.iloc[:,1:] = data.iloc[:,1:] / norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>요일</th>\n",
       "      <th>배추_거래량(kg)</th>\n",
       "      <th>배추_가격(원/kg)</th>\n",
       "      <th>무_거래량(kg)</th>\n",
       "      <th>무_가격(원/kg)</th>\n",
       "      <th>양파_거래량(kg)</th>\n",
       "      <th>양파_가격(원/kg)</th>\n",
       "      <th>건고추_거래량(kg)</th>\n",
       "      <th>건고추_가격(원/kg)</th>\n",
       "      <th>...</th>\n",
       "      <th>청상추_거래량(kg)</th>\n",
       "      <th>청상추_가격(원/kg)</th>\n",
       "      <th>백다다기_거래량(kg)</th>\n",
       "      <th>백다다기_가격(원/kg)</th>\n",
       "      <th>애호박_거래량(kg)</th>\n",
       "      <th>애호박_가격(원/kg)</th>\n",
       "      <th>캠벨얼리_거래량(kg)</th>\n",
       "      <th>캠벨얼리_가격(원/kg)</th>\n",
       "      <th>샤인마스캇_거래량(kg)</th>\n",
       "      <th>샤인마스캇_가격(원/kg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.015520</td>\n",
       "      <td>0.0658</td>\n",
       "      <td>0.020797</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>0.024437</td>\n",
       "      <td>0.6405</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.064389</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060900</td>\n",
       "      <td>0.511068</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>0.398376</td>\n",
       "      <td>0.023032</td>\n",
       "      <td>0.356152</td>\n",
       "      <td>0.000590</td>\n",
       "      <td>0.08056</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-03</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.273068</td>\n",
       "      <td>0.0956</td>\n",
       "      <td>0.440354</td>\n",
       "      <td>0.280882</td>\n",
       "      <td>0.460735</td>\n",
       "      <td>0.6175</td>\n",
       "      <td>0.001690</td>\n",
       "      <td>0.026130</td>\n",
       "      <td>...</td>\n",
       "      <td>0.457792</td>\n",
       "      <td>0.422302</td>\n",
       "      <td>0.227365</td>\n",
       "      <td>0.386475</td>\n",
       "      <td>0.745976</td>\n",
       "      <td>0.297728</td>\n",
       "      <td>0.001814</td>\n",
       "      <td>0.15540</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-05</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.224029</td>\n",
       "      <td>0.0884</td>\n",
       "      <td>0.368802</td>\n",
       "      <td>0.310294</td>\n",
       "      <td>0.416530</td>\n",
       "      <td>0.6065</td>\n",
       "      <td>0.002690</td>\n",
       "      <td>0.025416</td>\n",
       "      <td>...</td>\n",
       "      <td>0.387559</td>\n",
       "      <td>0.383287</td>\n",
       "      <td>0.067041</td>\n",
       "      <td>0.428410</td>\n",
       "      <td>0.278846</td>\n",
       "      <td>0.321334</td>\n",
       "      <td>0.005911</td>\n",
       "      <td>0.11412</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1728</th>\n",
       "      <td>2020-09-24</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.356409</td>\n",
       "      <td>0.3678</td>\n",
       "      <td>0.532584</td>\n",
       "      <td>0.727941</td>\n",
       "      <td>0.454038</td>\n",
       "      <td>0.4950</td>\n",
       "      <td>0.006813</td>\n",
       "      <td>0.111809</td>\n",
       "      <td>...</td>\n",
       "      <td>0.602816</td>\n",
       "      <td>0.249530</td>\n",
       "      <td>0.128151</td>\n",
       "      <td>0.566868</td>\n",
       "      <td>0.376438</td>\n",
       "      <td>0.505459</td>\n",
       "      <td>0.338341</td>\n",
       "      <td>0.14480</td>\n",
       "      <td>0.740842</td>\n",
       "      <td>0.273500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1729</th>\n",
       "      <td>2020-09-25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.360848</td>\n",
       "      <td>0.3578</td>\n",
       "      <td>0.486887</td>\n",
       "      <td>0.743382</td>\n",
       "      <td>0.412859</td>\n",
       "      <td>0.4775</td>\n",
       "      <td>0.004562</td>\n",
       "      <td>0.135188</td>\n",
       "      <td>...</td>\n",
       "      <td>0.645499</td>\n",
       "      <td>0.231212</td>\n",
       "      <td>0.141775</td>\n",
       "      <td>0.566490</td>\n",
       "      <td>0.436066</td>\n",
       "      <td>0.495279</td>\n",
       "      <td>0.321862</td>\n",
       "      <td>0.14472</td>\n",
       "      <td>0.794687</td>\n",
       "      <td>0.271100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1730</th>\n",
       "      <td>2020-09-26</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.318814</td>\n",
       "      <td>0.3520</td>\n",
       "      <td>0.442875</td>\n",
       "      <td>0.790441</td>\n",
       "      <td>0.415758</td>\n",
       "      <td>0.4805</td>\n",
       "      <td>0.002318</td>\n",
       "      <td>0.131764</td>\n",
       "      <td>...</td>\n",
       "      <td>0.727384</td>\n",
       "      <td>0.208633</td>\n",
       "      <td>0.148668</td>\n",
       "      <td>0.578957</td>\n",
       "      <td>0.469269</td>\n",
       "      <td>0.456182</td>\n",
       "      <td>0.349917</td>\n",
       "      <td>0.14764</td>\n",
       "      <td>0.819581</td>\n",
       "      <td>0.265900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1731</th>\n",
       "      <td>2020-09-27</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.004874</td>\n",
       "      <td>0.6132</td>\n",
       "      <td>0.009903</td>\n",
       "      <td>0.837500</td>\n",
       "      <td>0.003630</td>\n",
       "      <td>0.5280</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>0.130728</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001711</td>\n",
       "      <td>0.225567</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.700227</td>\n",
       "      <td>0.002962</td>\n",
       "      <td>0.479788</td>\n",
       "      <td>0.014572</td>\n",
       "      <td>0.14268</td>\n",
       "      <td>0.025464</td>\n",
       "      <td>0.267475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1732</th>\n",
       "      <td>2020-09-28</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.461603</td>\n",
       "      <td>0.3734</td>\n",
       "      <td>0.711839</td>\n",
       "      <td>0.843382</td>\n",
       "      <td>0.444954</td>\n",
       "      <td>0.4820</td>\n",
       "      <td>0.003942</td>\n",
       "      <td>0.128907</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.230603</td>\n",
       "      <td>0.251959</td>\n",
       "      <td>0.542690</td>\n",
       "      <td>0.802724</td>\n",
       "      <td>0.410446</td>\n",
       "      <td>0.403829</td>\n",
       "      <td>0.15044</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.274950</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1733 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date        요일  배추_거래량(kg)  배추_가격(원/kg)  무_거래량(kg)  무_가격(원/kg)  \\\n",
       "0     2016-01-01  0.000000    0.000000       0.0000   0.000000    0.000000   \n",
       "1     2016-01-02  0.166667    0.015520       0.0658   0.020797    0.264706   \n",
       "2     2016-01-03  0.333333    0.000000       0.0000   0.000000    0.000000   \n",
       "3     2016-01-04  0.500000    0.273068       0.0956   0.440354    0.280882   \n",
       "4     2016-01-05  0.666667    0.224029       0.0884   0.368802    0.310294   \n",
       "...          ...       ...         ...          ...        ...         ...   \n",
       "1728  2020-09-24  1.000000    0.356409       0.3678   0.532584    0.727941   \n",
       "1729  2020-09-25  0.000000    0.360848       0.3578   0.486887    0.743382   \n",
       "1730  2020-09-26  0.166667    0.318814       0.3520   0.442875    0.790441   \n",
       "1731  2020-09-27  0.333333    0.004874       0.6132   0.009903    0.837500   \n",
       "1732  2020-09-28  0.500000    0.461603       0.3734   0.711839    0.843382   \n",
       "\n",
       "      양파_거래량(kg)  양파_가격(원/kg)  건고추_거래량(kg)  건고추_가격(원/kg)  ...  청상추_거래량(kg)  \\\n",
       "0       0.000000       0.0000     0.000000      0.000000  ...     0.000000   \n",
       "1       0.024437       0.6405     0.000007      0.064389  ...     0.060900   \n",
       "2       0.000000       0.0000     0.000000      0.000000  ...     0.000000   \n",
       "3       0.460735       0.6175     0.001690      0.026130  ...     0.457792   \n",
       "4       0.416530       0.6065     0.002690      0.025416  ...     0.387559   \n",
       "...          ...          ...          ...           ...  ...          ...   \n",
       "1728    0.454038       0.4950     0.006813      0.111809  ...     0.602816   \n",
       "1729    0.412859       0.4775     0.004562      0.135188  ...     0.645499   \n",
       "1730    0.415758       0.4805     0.002318      0.131764  ...     0.727384   \n",
       "1731    0.003630       0.5280     0.000145      0.130728  ...     0.001711   \n",
       "1732    0.444954       0.4820     0.003942      0.128907  ...     1.000000   \n",
       "\n",
       "      청상추_가격(원/kg)  백다다기_거래량(kg)  백다다기_가격(원/kg)  애호박_거래량(kg)  애호박_가격(원/kg)  \\\n",
       "0         0.000000      0.000000       0.000000     0.000000      0.000000   \n",
       "1         0.511068      0.000197       0.398376     0.023032      0.356152   \n",
       "2         0.000000      0.000000       0.000000     0.000000      0.000000   \n",
       "3         0.422302      0.227365       0.386475     0.745976      0.297728   \n",
       "4         0.383287      0.067041       0.428410     0.278846      0.321334   \n",
       "...            ...           ...            ...          ...           ...   \n",
       "1728      0.249530      0.128151       0.566868     0.376438      0.505459   \n",
       "1729      0.231212      0.141775       0.566490     0.436066      0.495279   \n",
       "1730      0.208633      0.148668       0.578957     0.469269      0.456182   \n",
       "1731      0.225567      0.000129       0.700227     0.002962      0.479788   \n",
       "1732      0.230603      0.251959       0.542690     0.802724      0.410446   \n",
       "\n",
       "      캠벨얼리_거래량(kg)  캠벨얼리_가격(원/kg)  샤인마스캇_거래량(kg)  샤인마스캇_가격(원/kg)  \n",
       "0         0.000000        0.00000       0.000000        0.000000  \n",
       "1         0.000590        0.08056       0.000000        0.000000  \n",
       "2         0.000000        0.00000       0.000000        0.000000  \n",
       "3         0.001814        0.15540       0.000000        0.000000  \n",
       "4         0.005911        0.11412       0.000000        0.000000  \n",
       "...            ...            ...            ...             ...  \n",
       "1728      0.338341        0.14480       0.740842        0.273500  \n",
       "1729      0.321862        0.14472       0.794687        0.271100  \n",
       "1730      0.349917        0.14764       0.819581        0.265900  \n",
       "1731      0.014572        0.14268       0.025464        0.267475  \n",
       "1732      0.403829        0.15044       1.000000        0.274950  \n",
       "\n",
       "[1733 rows x 44 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\") # GPU 사용\n",
    "target_n = 21 # 맞춰야하는 품목/품종의 수\n",
    "learning_rate = 5e-4 # 학습률\n",
    "BATCH_SIZE = 128 # 배치사이즈\n",
    "EPOCHS = 50 # 총 eopochs\n",
    "teacher_forcing = False # 교사강요 설정\n",
    "n_layers = 3 # rnn레이어 층\n",
    "dropout = 0.2 # 드롭아웃\n",
    "window_size = 28 # 인코더 시퀀스 길이\n",
    "future_size = 28 # 디코더 시퀀스 길이\n",
    "hidden_dim = 128 # rnn 히든차원\n",
    "save_path = f'./models/best_model.pt' # 모델 저장 경로"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "과거 28일을 보고 미래 28일을 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = [] \n",
    "y_data = [] \n",
    "for i in range(data.shape[0]-window_size-future_size): \n",
    "    x = data.iloc[i:i+window_size, 1:].to_numpy() \n",
    "    y = data.iloc[i+window_size:i+window_size+future_size, 3::2].to_numpy() \n",
    "    y_0 = np.zeros([1, y.shape[1]]) # 디코더 첫 입력값 추가 \n",
    "    x_data.append(x) \n",
    "    y_data.append(np.concatenate([y_0, y], axis = 0)) \n",
    "    \n",
    "x_data = np.array(x_data) \n",
    "y_data = np.array(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1677, 28, 43), (1677, 29, 21))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data.shape, y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x_data, y_data, random_state = 42, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1509, 28, 43), (168, 28, 43), (1509, 29, 21), (168, 29, 21))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset): \n",
    "    def __init__(self, encoder_input, decoder_input): \n",
    "        self.encoder_input = encoder_input\n",
    "        self.decoder_input = decoder_input \n",
    "        \n",
    "    def __len__(self): \n",
    "        return len(self.encoder_input) \n",
    "    \n",
    "    def __getitem__(self, i):  \n",
    "        return {\n",
    "            'encoder_input': torch.tensor(self.encoder_input[i], dtype=torch.float32), \n",
    "            'decoder_input': torch.tensor(self.decoder_input[i], dtype=torch.float32) \n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(x_train, y_train)\n",
    "val_dataset = CustomDataset(x_val, y_val) \n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle = True) \n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size = BATCH_SIZE, shuffle = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_batch = next(iter(train_dataloader)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 28, 43]), torch.Size([128, 29, 21]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_batch['encoder_input'].shape, sample_batch['decoder_input'].shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module): \n",
    "    def __init__(self, input_dim, hidden_dim, n_layers, dropout): \n",
    "        super().__init__() \n",
    "        self.n_layers = n_layers \n",
    "        self.rnn = nn.GRU(input_dim, hidden_dim, n_layers, dropout=dropout)\n",
    "        self.dropout = nn.Dropout(dropout) \n",
    "        \n",
    "    def forward(self, inp_seq): \n",
    "        inp_seq = inp_seq.permute(1,0,2) \n",
    "        outputs, hidden = self.rnn(inp_seq) \n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(nn.Module): \n",
    "    def __init__(self, dec_output_dim, units): \n",
    "        super(BahdanauAttention, self).__init__() \n",
    "        self.W1 = nn.Linear(dec_output_dim, units) \n",
    "        self.W2 = nn.Linear(dec_output_dim, units) \n",
    "        self.V = nn.Linear(dec_output_dim, 1) \n",
    "    \n",
    "    def forward(self, hidden, enc_output): \n",
    "        query_with_time_axis = hidden.unsqueeze(1) \n",
    "        score = self.V(torch.tanh(self.W1(query_with_time_axis) + self.W2(enc_output))) \n",
    "        attention_weights = torch.softmax(score, axis=1) \n",
    "        context_vector = attention_weights * enc_output \n",
    "        context_vector = torch.sum(context_vector, dim = 1) \n",
    "        return context_vector, attention_weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module): \n",
    "    def __init__(self, dec_feature_size, encoder_hidden_dim, output_dim, decoder_hidden_dim, n_layers, dropout, attention):\n",
    "        super().__init__() \n",
    "        self.output_dim = output_dim \n",
    "        self.decoder_hidden_dim = decoder_hidden_dim \n",
    "        self.n_layers = n_layers \n",
    "        self.attention = attention \n",
    "        self.layer = nn.Linear(dec_feature_size, encoder_hidden_dim) \n",
    "        self.rnn = nn.GRU(encoder_hidden_dim*2, decoder_hidden_dim, n_layers, dropout=dropout) \n",
    "        self.fc_out = nn.Linear(hidden_dim, output_dim) \n",
    "        self.dropout = nn.Dropout(dropout) \n",
    "    \n",
    "    def forward(self, enc_output, dec_input, hidden): \n",
    "        dec_input = self.layer(dec_input) \n",
    "        context_vector, attention_weight = self.attention(hidden, enc_output) \n",
    "        dec_input = torch.cat([torch.sum(context_vector, dim=0), dec_input], dim=1) \n",
    "        dec_input = dec_input.unsqueeze(0) \n",
    "        output, hidden = self.rnn(dec_input, hidden) \n",
    "        prediction = self.fc_out(output.sum(0)) \n",
    "        return prediction, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module): \n",
    "    def __init__(self, encoder, decoder, attention): \n",
    "        super().__init__() \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder \n",
    "    \n",
    "    def forward(self, encoder_input, decoder_input, teacher_forcing=False):\n",
    "        batch_size = decoder_input.size(0)\n",
    "        trg_len = decoder_input.size(1) \n",
    "        outputs = torch.zeros(batch_size, trg_len-1, self.decoder.output_dim).to(device) \n",
    "        enc_output, hidden = self.encoder(encoder_input) \n",
    "        dec_input = decoder_input[:,0] \n",
    "        for t in range(1, trg_len): \n",
    "            output, hidden = self.decoder(enc_output, dec_input, hidden) \n",
    "            outputs[:,t-1] = output\n",
    "            if teacher_forcing == True: \n",
    "                dec_input = decoder_input[:,t] \n",
    "            else: \n",
    "                dec_input = output \n",
    "        \n",
    "        return outputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(input_dim = x_data.shape[-1], hidden_dim = hidden_dim, n_layers = n_layers, dropout=dropout) \n",
    "attention = BahdanauAttention(dec_output_dim=hidden_dim, units=hidden_dim) \n",
    "decoder = Decoder(\n",
    "    dec_feature_size = target_n, encoder_hidden_dim=hidden_dim, output_dim=target_n, \n",
    "    decoder_hidden_dim=hidden_dim, n_layers=n_layers, dropout=dropout, \n",
    "    attention=attention \n",
    ")\n",
    "\n",
    "model = Seq2Seq(encoder, decoder, attention) \n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_custom_metric(pred, true): \n",
    "    pred = pred[:, [6,13,27]] \n",
    "    true = true[:, [6,13,27]] \n",
    "    target = torch.where(true!=0) \n",
    "    true = true[target] \n",
    "    pred = pred[target] \n",
    "    score = torch.mean(torch.abs((true-pred)/true)) \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) \n",
    "criterion = nn.L1Loss() # mae \n",
    "custom_metric = my_custom_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(batch_item, epoch, batch, training, teacher_forcing):\n",
    "    encoder_input = batch_item['encoder_input'].to(device)\n",
    "    decoder_input = batch_item['decoder_input'].to(device)\n",
    "    if training is True:\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        with torch.cuda.amp.autocast():\n",
    "            output = model(encoder_input, decoder_input, teacher_forcing)\n",
    "            loss = criterion(output, decoder_input[:,1:])\n",
    "            score = custom_metric(output, decoder_input[:,1:])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        return loss, score\n",
    "    else:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            output = model(encoder_input, decoder_input, False)\n",
    "            loss = criterion(output, decoder_input[:,1:])\n",
    "            score = custom_metric(output, decoder_input[:,1:])\n",
    "        return loss, score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  7.30it/s, Epoch=1, Loss=0.267926, Total Loss=0.267926, Score=1.004782, Total Score=1.004782]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:01,  8.44it/s, Epoch=1, Loss=0.138242, Total Loss=0.178004, Score=0.376480, Total Score=0.588541]\n",
      "2it [00:00, 29.17it/s, Epoch=1, Val Loss=0.126005, Total Val Loss=0.130007, Val Score=0.326199, Total Val Score=0.335177]\n",
      "1it [00:00,  8.68it/s, Epoch=2, Loss=0.137488, Total Loss=0.137488, Score=0.362635, Total Score=0.362635]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:01,  9.05it/s, Epoch=2, Loss=0.123409, Total Loss=0.130461, Score=0.529792, Total Score=0.368716]\n",
      "2it [00:00, 31.29it/s, Epoch=2, Val Loss=0.122719, Total Val Loss=0.122099, Val Score=0.314275, Total Val Score=0.313596]\n",
      "1it [00:00,  9.12it/s, Epoch=3, Loss=0.124408, Total Loss=0.124408, Score=0.330488, Total Score=0.330488]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:01,  8.24it/s, Epoch=3, Loss=0.122465, Total Loss=0.121748, Score=0.306282, Total Score=0.336492]\n",
      "2it [00:00, 24.31it/s, Epoch=3, Val Loss=0.117179, Total Val Loss=0.116600, Val Score=0.275169, Total Val Score=0.282790]\n",
      "1it [00:00,  7.85it/s, Epoch=4, Loss=0.116988, Total Loss=0.116988, Score=0.300214, Total Score=0.300214]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:01,  7.92it/s, Epoch=4, Loss=0.114470, Total Loss=0.117537, Score=0.271818, Total Score=0.293988]\n",
      "2it [00:00, 22.83it/s, Epoch=4, Val Loss=0.111954, Total Val Loss=0.112843, Val Score=0.267442, Total Val Score=0.269565]\n",
      "1it [00:00,  7.74it/s, Epoch=5, Loss=0.121786, Total Loss=0.121786, Score=0.377126, Total Score=0.377126]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:01,  7.12it/s, Epoch=5, Loss=0.112012, Total Loss=0.114576, Score=0.271476, Total Score=0.293416]\n",
      "2it [00:00, 24.12it/s, Epoch=5, Val Loss=0.114556, Total Val Loss=0.112247, Val Score=0.264604, Total Val Score=0.262229]\n",
      "1it [00:00,  8.21it/s, Epoch=6, Loss=0.110660, Total Loss=0.110660, Score=0.260171, Total Score=0.260171]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:01,  8.04it/s, Epoch=6, Loss=0.105854, Total Loss=0.111611, Score=0.253998, Total Score=0.278812]\n",
      "2it [00:00, 24.98it/s, Epoch=6, Val Loss=0.113484, Total Val Loss=0.109940, Val Score=0.256852, Total Val Score=0.257876]\n",
      "1it [00:00,  8.16it/s, Epoch=7, Loss=0.110699, Total Loss=0.110699, Score=0.272376, Total Score=0.272376]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:01,  8.03it/s, Epoch=7, Loss=0.109263, Total Loss=0.109218, Score=0.253628, Total Score=0.279803]\n",
      "2it [00:00, 23.55it/s, Epoch=7, Val Loss=0.107658, Total Val Loss=0.107469, Val Score=0.254021, Total Val Score=0.258046]\n",
      "1it [00:00,  8.80it/s, Epoch=8, Loss=0.108857, Total Loss=0.108857, Score=0.266009, Total Score=0.266009]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:01,  8.27it/s, Epoch=8, Loss=0.107576, Total Loss=0.107304, Score=0.241181, Total Score=0.264733]\n",
      "2it [00:00, 26.86it/s, Epoch=8, Val Loss=0.103238, Total Val Loss=0.104387, Val Score=0.238801, Total Val Score=0.245676]\n",
      "1it [00:00,  8.15it/s, Epoch=9, Loss=0.105412, Total Loss=0.105412, Score=0.260493, Total Score=0.260493]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:01,  8.62it/s, Epoch=9, Loss=0.108776, Total Loss=0.105133, Score=0.237136, Total Score=0.252788]\n",
      "2it [00:00, 27.35it/s, Epoch=9, Val Loss=0.105653, Total Val Loss=0.103404, Val Score=0.241169, Total Val Score=0.235267]\n",
      "1it [00:00,  8.92it/s, Epoch=10, Loss=0.102980, Total Loss=0.102980, Score=0.231371, Total Score=0.231371]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:01,  8.93it/s, Epoch=10, Loss=0.102436, Total Loss=0.103560, Score=0.225058, Total Score=0.246166]\n",
      "2it [00:00, 29.84it/s, Epoch=10, Val Loss=0.100332, Total Val Loss=0.101287, Val Score=0.231406, Total Val Score=0.232742]\n",
      "1it [00:00,  8.71it/s, Epoch=11, Loss=0.107703, Total Loss=0.107703, Score=0.235780, Total Score=0.235780]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:01,  8.60it/s, Epoch=11, Loss=0.107363, Total Loss=0.103106, Score=0.233072, Total Score=0.245376]\n",
      "2it [00:00, 28.35it/s, Epoch=11, Val Loss=0.104876, Total Val Loss=0.102656, Val Score=0.231024, Total Val Score=0.230855]\n",
      "1it [00:00,  8.74it/s, Epoch=12, Loss=0.104542, Total Loss=0.104542, Score=0.285780, Total Score=0.285780]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:01,  8.51it/s, Epoch=12, Loss=0.100672, Total Loss=0.101905, Score=0.229893, Total Score=0.238806]\n",
      "2it [00:00, 28.23it/s, Epoch=12, Val Loss=0.102253, Total Val Loss=0.100558, Val Score=0.232631, Total Val Score=0.227551]\n",
      "1it [00:00,  8.49it/s, Epoch=13, Loss=0.104944, Total Loss=0.104944, Score=0.226454, Total Score=0.226454]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:01,  8.40it/s, Epoch=13, Loss=0.095047, Total Loss=0.100599, Score=0.211027, Total Score=0.234571]\n",
      "2it [00:00, 28.81it/s, Epoch=13, Val Loss=0.098163, Total Val Loss=0.098329, Val Score=0.226983, Total Val Score=0.221403]\n",
      "1it [00:00,  8.82it/s, Epoch=14, Loss=0.101627, Total Loss=0.101627, Score=0.216980, Total Score=0.216980]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:01,  8.69it/s, Epoch=14, Loss=0.102949, Total Loss=0.099934, Score=0.220047, Total Score=0.234963]\n",
      "2it [00:00, 29.33it/s, Epoch=14, Val Loss=0.096871, Total Val Loss=0.097373, Val Score=0.213898, Total Val Score=0.215937]\n",
      "1it [00:00,  8.16it/s, Epoch=15, Loss=0.099710, Total Loss=0.099710, Score=0.219021, Total Score=0.219021]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:01,  7.89it/s, Epoch=15, Loss=0.094420, Total Loss=0.098860, Score=0.204614, Total Score=0.229179]\n",
      "2it [00:00, 25.02it/s, Epoch=15, Val Loss=0.098744, Total Val Loss=0.097576, Val Score=0.218091, Total Val Score=0.215183]\n",
      "1it [00:00,  8.02it/s, Epoch=16, Loss=0.102210, Total Loss=0.102210, Score=0.212666, Total Score=0.212666]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:01,  8.37it/s, Epoch=16, Loss=0.099894, Total Loss=0.098550, Score=0.294851, Total Score=0.225946]\n",
      "2it [00:00, 25.13it/s, Epoch=16, Val Loss=0.091873, Total Val Loss=0.094578, Val Score=0.214724, Total Val Score=0.211491]\n",
      "1it [00:00,  8.26it/s, Epoch=17, Loss=0.097875, Total Loss=0.097875, Score=0.211508, Total Score=0.211508]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:01,  8.29it/s, Epoch=17, Loss=0.094476, Total Loss=0.097882, Score=0.271251, Total Score=0.224975]\n",
      "2it [00:00, 25.98it/s, Epoch=17, Val Loss=0.091955, Total Val Loss=0.094521, Val Score=0.205540, Total Val Score=0.208074]\n",
      "1it [00:00,  7.63it/s, Epoch=18, Loss=0.095646, Total Loss=0.095646, Score=0.205630, Total Score=0.205630]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:01,  6.39it/s, Epoch=18, Loss=0.097684, Total Loss=0.096975, Score=0.211080, Total Score=0.219927]\n",
      "2it [00:00, 23.97it/s, Epoch=18, Val Loss=0.096849, Total Val Loss=0.096090, Val Score=0.210049, Total Val Score=0.211308]\n",
      "1it [00:00,  8.41it/s, Epoch=19, Loss=0.101080, Total Loss=0.101080, Score=0.212619, Total Score=0.212619]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:01,  8.53it/s, Epoch=19, Loss=0.097641, Total Loss=0.096845, Score=0.205885, Total Score=0.222122]\n",
      "2it [00:00, 27.86it/s, Epoch=19, Val Loss=0.092607, Total Val Loss=0.093893, Val Score=0.218741, Total Val Score=0.210996]\n",
      "1it [00:00,  7.97it/s, Epoch=20, Loss=0.097826, Total Loss=0.097826, Score=0.205059, Total Score=0.205059]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:01,  8.29it/s, Epoch=20, Loss=0.095154, Total Loss=0.095689, Score=0.307462, Total Score=0.219323]\n",
      "2it [00:00, 27.06it/s, Epoch=20, Val Loss=0.098664, Total Val Loss=0.095447, Val Score=0.199807, Total Val Score=0.201058]\n",
      "1it [00:00,  8.22it/s, Epoch=21, Loss=0.098392, Total Loss=0.098392, Score=0.202107, Total Score=0.202107]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:01,  8.55it/s, Epoch=21, Loss=0.094090, Total Loss=0.095092, Score=0.199521, Total Score=0.214737]\n",
      "2it [00:00, 29.26it/s, Epoch=21, Val Loss=0.097278, Total Val Loss=0.094709, Val Score=0.189581, Total Val Score=0.195832]\n",
      "1it [00:00,  7.48it/s, Epoch=22, Loss=0.093260, Total Loss=0.093260, Score=0.195619, Total Score=0.195619]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:01,  7.63it/s, Epoch=22, Loss=0.093532, Total Loss=0.094531, Score=0.197144, Total Score=0.210133]\n",
      "2it [00:00, 26.53it/s, Epoch=22, Val Loss=0.092532, Total Val Loss=0.092962, Val Score=0.198352, Total Val Score=0.199440]\n",
      "1it [00:00,  8.14it/s, Epoch=23, Loss=0.093696, Total Loss=0.093696, Score=0.189314, Total Score=0.189314]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:01,  8.02it/s, Epoch=23, Loss=0.093931, Total Loss=0.094154, Score=0.191521, Total Score=0.210511]\n",
      "2it [00:00, 28.41it/s, Epoch=23, Val Loss=0.089774, Total Val Loss=0.091308, Val Score=0.186483, Total Val Score=0.191849]\n",
      "1it [00:00,  7.98it/s, Epoch=24, Loss=0.095288, Total Loss=0.095288, Score=0.195127, Total Score=0.195127]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:01,  8.60it/s, Epoch=24, Loss=0.092216, Total Loss=0.093705, Score=0.188300, Total Score=0.208334]\n",
      "2it [00:00, 29.42it/s, Epoch=24, Val Loss=0.094107, Total Val Loss=0.092715, Val Score=0.195136, Total Val Score=0.193617]\n",
      "1it [00:00,  8.86it/s, Epoch=25, Loss=0.093613, Total Loss=0.093613, Score=0.186929, Total Score=0.186929]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:01,  8.17it/s, Epoch=25, Loss=0.088572, Total Loss=0.093069, Score=0.189056, Total Score=0.204620]\n",
      "2it [00:00, 30.64it/s, Epoch=25, Val Loss=0.090139, Total Val Loss=0.090814, Val Score=0.187580, Total Val Score=0.188899]\n",
      "1it [00:00,  8.89it/s, Epoch=26, Loss=0.094066, Total Loss=0.094066, Score=0.186403, Total Score=0.186403]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:01,  8.52it/s, Epoch=26, Loss=0.096748, Total Loss=0.092455, Score=0.184174, Total Score=0.203961]\n",
      "2it [00:00, 30.11it/s, Epoch=26, Val Loss=0.092104, Total Val Loss=0.091094, Val Score=0.184573, Total Val Score=0.187020]\n",
      "1it [00:00,  8.79it/s, Epoch=27, Loss=0.094292, Total Loss=0.094292, Score=0.253129, Total Score=0.253129]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:01,  8.59it/s, Epoch=27, Loss=0.088243, Total Loss=0.091773, Score=0.179293, Total Score=0.198941]\n",
      "2it [00:00, 28.97it/s, Epoch=27, Val Loss=0.087761, Total Val Loss=0.089299, Val Score=0.178613, Total Val Score=0.183714]\n",
      "1it [00:00,  7.95it/s, Epoch=28, Loss=0.092415, Total Loss=0.092415, Score=0.254024, Total Score=0.254024]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:01,  8.17it/s, Epoch=28, Loss=0.089474, Total Loss=0.091378, Score=0.186238, Total Score=0.199744]\n",
      "2it [00:00, 29.38it/s, Epoch=28, Val Loss=0.090151, Total Val Loss=0.090617, Val Score=0.202738, Total Val Score=0.195021]\n",
      "1it [00:00,  8.77it/s, Epoch=29, Loss=0.095469, Total Loss=0.095469, Score=0.246443, Total Score=0.246443]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:01,  8.63it/s, Epoch=29, Loss=0.090932, Total Loss=0.091391, Score=0.187760, Total Score=0.198533]\n",
      "2it [00:00, 29.73it/s, Epoch=29, Val Loss=0.091231, Total Val Loss=0.090279, Val Score=0.188508, Total Val Score=0.185746]\n",
      "1it [00:00,  8.61it/s, Epoch=30, Loss=0.091735, Total Loss=0.091735, Score=0.177679, Total Score=0.177679]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:01,  8.21it/s, Epoch=30, Loss=0.088998, Total Loss=0.090620, Score=0.178322, Total Score=0.196022]\n",
      "2it [00:00, 29.32it/s, Epoch=30, Val Loss=0.086010, Total Val Loss=0.087851, Val Score=0.171558, Total Val Score=0.177719]\n",
      "1it [00:00,  8.49it/s, Epoch=31, Loss=0.089767, Total Loss=0.089767, Score=0.169369, Total Score=0.169369]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:01,  7.41it/s, Epoch=31, Loss=0.087284, Total Loss=0.089887, Score=0.172542, Total Score=0.192706]\n",
      "2it [00:00, 17.63it/s, Epoch=31, Val Loss=0.086031, Total Val Loss=0.087990, Val Score=0.190213, Total Val Score=0.185238]\n",
      "1it [00:00,  7.41it/s, Epoch=32, Loss=0.091538, Total Loss=0.091538, Score=0.179498, Total Score=0.179498]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:01,  7.89it/s, Epoch=32, Loss=0.085676, Total Loss=0.089328, Score=0.172844, Total Score=0.192580]\n",
      "2it [00:00, 28.39it/s, Epoch=32, Val Loss=0.089802, Total Val Loss=0.088499, Val Score=0.174118, Total Val Score=0.176302]\n",
      "1it [00:00,  8.68it/s, Epoch=33, Loss=0.089990, Total Loss=0.089990, Score=0.239009, Total Score=0.239009]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:01,  8.55it/s, Epoch=33, Loss=0.087241, Total Loss=0.088736, Score=0.171393, Total Score=0.188099]\n",
      "2it [00:00, 26.77it/s, Epoch=33, Val Loss=0.083656, Total Val Loss=0.086115, Val Score=0.180331, Total Val Score=0.176957]\n",
      "1it [00:00,  8.74it/s, Epoch=34, Loss=0.087616, Total Loss=0.087616, Score=0.169750, Total Score=0.169750]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:01,  8.74it/s, Epoch=34, Loss=0.087614, Total Loss=0.088407, Score=0.174997, Total Score=0.188237]\n",
      "2it [00:00, 24.92it/s, Epoch=34, Val Loss=0.084617, Total Val Loss=0.086218, Val Score=0.175400, Total Val Score=0.174333]\n",
      "1it [00:00,  8.11it/s, Epoch=35, Loss=0.088978, Total Loss=0.088978, Score=0.234252, Total Score=0.234252]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:02,  4.51it/s, Epoch=35, Loss=0.086601, Total Loss=0.088045, Score=0.163444, Total Score=0.184637]\n",
      "2it [00:00, 27.82it/s, Epoch=35, Val Loss=0.081559, Total Val Loss=0.084800, Val Score=0.159271, Total Val Score=0.168120]\n",
      "1it [00:00,  7.12it/s, Epoch=36, Loss=0.090208, Total Loss=0.090208, Score=0.167658, Total Score=0.167658]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:04,  2.95it/s, Epoch=36, Loss=0.084056, Total Loss=0.087566, Score=0.163214, Total Score=0.183922]\n",
      "2it [00:00, 29.67it/s, Epoch=36, Val Loss=0.084531, Total Val Loss=0.085540, Val Score=0.161794, Total Val Score=0.166456]\n",
      "1it [00:00,  8.77it/s, Epoch=37, Loss=0.088803, Total Loss=0.088803, Score=0.223779, Total Score=0.223779]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:02,  4.85it/s, Epoch=37, Loss=0.085647, Total Loss=0.086922, Score=0.168745, Total Score=0.179929]\n",
      "2it [00:00, 28.57it/s, Epoch=37, Val Loss=0.081340, Total Val Loss=0.083995, Val Score=0.165147, Total Val Score=0.166086]\n",
      "1it [00:00,  8.80it/s, Epoch=38, Loss=0.083354, Total Loss=0.083354, Score=0.161483, Total Score=0.161483]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:01,  8.69it/s, Epoch=38, Loss=0.085620, Total Loss=0.086554, Score=0.168162, Total Score=0.180306]\n",
      "2it [00:00, 28.27it/s, Epoch=38, Val Loss=0.084142, Total Val Loss=0.084782, Val Score=0.153639, Total Val Score=0.162438]\n",
      "1it [00:00,  8.58it/s, Epoch=39, Loss=0.089289, Total Loss=0.089289, Score=0.288244, Total Score=0.288244]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:01,  7.85it/s, Epoch=39, Loss=0.086377, Total Loss=0.086245, Score=0.164238, Total Score=0.179715]\n",
      "2it [00:00, 29.39it/s, Epoch=39, Val Loss=0.086282, Total Val Loss=0.085241, Val Score=0.181174, Total Val Score=0.170337]\n",
      "1it [00:00,  8.82it/s, Epoch=40, Loss=0.085937, Total Loss=0.085937, Score=0.223777, Total Score=0.223777]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:01,  8.45it/s, Epoch=40, Loss=0.080667, Total Loss=0.085774, Score=0.157260, Total Score=0.177952]\n",
      "2it [00:00, 24.56it/s, Epoch=40, Val Loss=0.080829, Total Val Loss=0.083239, Val Score=0.158849, Total Val Score=0.163195]\n",
      "1it [00:00,  7.85it/s, Epoch=41, Loss=0.085915, Total Loss=0.085915, Score=0.161993, Total Score=0.161993]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:01,  7.54it/s, Epoch=41, Loss=0.085899, Total Loss=0.085654, Score=0.162020, Total Score=0.177456]\n",
      "2it [00:00, 29.49it/s, Epoch=41, Val Loss=0.080052, Total Val Loss=0.082746, Val Score=0.152553, Total Val Score=0.159411]\n",
      "1it [00:00,  8.15it/s, Epoch=42, Loss=0.086258, Total Loss=0.086258, Score=0.160218, Total Score=0.160218]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:02,  5.36it/s, Epoch=42, Loss=0.083780, Total Loss=0.085151, Score=0.231369, Total Score=0.175869]\n",
      "2it [00:00, 29.43it/s, Epoch=42, Val Loss=0.087778, Total Val Loss=0.085000, Val Score=0.179258, Total Val Score=0.168313]\n",
      "1it [00:00,  8.73it/s, Epoch=43, Loss=0.084049, Total Loss=0.084049, Score=0.160950, Total Score=0.160950]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:02,  4.86it/s, Epoch=43, Loss=0.083331, Total Loss=0.084570, Score=0.160347, Total Score=0.173341]\n",
      "2it [00:00, 29.92it/s, Epoch=43, Val Loss=0.075781, Total Val Loss=0.080408, Val Score=0.155666, Total Val Score=0.156760]\n",
      "1it [00:00,  8.66it/s, Epoch=44, Loss=0.082416, Total Loss=0.082416, Score=0.159341, Total Score=0.159341]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:04,  2.55it/s, Epoch=44, Loss=0.081327, Total Loss=0.084080, Score=0.235752, Total Score=0.174230]\n",
      "2it [00:00, 15.78it/s, Epoch=44, Val Loss=0.084869, Total Val Loss=0.083680, Val Score=0.162603, Total Val Score=0.160972]\n",
      "1it [00:00,  6.47it/s, Epoch=45, Loss=0.083312, Total Loss=0.083312, Score=0.155806, Total Score=0.155806]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:06,  1.76it/s, Epoch=45, Loss=0.083818, Total Loss=0.083887, Score=0.239562, Total Score=0.173899]\n",
      "2it [00:00, 22.97it/s, Epoch=45, Val Loss=0.081775, Total Val Loss=0.082258, Val Score=0.152424, Total Val Score=0.157031]\n",
      "1it [00:00,  5.39it/s, Epoch=46, Loss=0.082545, Total Loss=0.082545, Score=0.151732, Total Score=0.151732]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:02,  4.78it/s, Epoch=46, Loss=0.086407, Total Loss=0.083666, Score=0.159516, Total Score=0.169355]\n",
      "2it [00:00, 17.21it/s, Epoch=46, Val Loss=0.082318, Total Val Loss=0.082217, Val Score=0.150418, Total Val Score=0.154809]\n",
      "1it [00:00,  6.06it/s, Epoch=47, Loss=0.082762, Total Loss=0.082762, Score=0.151527, Total Score=0.151527]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:01,  6.25it/s, Epoch=47, Loss=0.085637, Total Loss=0.083324, Score=0.151932, Total Score=0.168454]\n",
      "2it [00:00, 27.46it/s, Epoch=47, Val Loss=0.082684, Total Val Loss=0.081960, Val Score=0.155948, Total Val Score=0.155178]\n",
      "1it [00:00,  8.64it/s, Epoch=48, Loss=0.080836, Total Loss=0.080836, Score=0.145467, Total Score=0.145467]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:01,  7.82it/s, Epoch=48, Loss=0.083984, Total Loss=0.082890, Score=0.145383, Total Score=0.165441]\n",
      "2it [00:00, 18.13it/s, Epoch=48, Val Loss=0.082711, Total Val Loss=0.081652, Val Score=0.167445, Total Val Score=0.158005]\n",
      "1it [00:00,  7.34it/s, Epoch=49, Loss=0.079405, Total Loss=0.079405, Score=0.206630, Total Score=0.206630]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:01,  8.37it/s, Epoch=49, Loss=0.079783, Total Loss=0.082431, Score=0.223235, Total Score=0.165143]\n",
      "2it [00:00, 28.11it/s, Epoch=49, Val Loss=0.077825, Total Val Loss=0.079807, Val Score=0.149297, Total Val Score=0.151431]\n",
      "1it [00:00,  8.76it/s, Epoch=50, Loss=0.082471, Total Loss=0.082471, Score=0.150900, Total Score=0.150900]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:01,  8.66it/s, Epoch=50, Loss=0.082251, Total Loss=0.082110, Score=0.149114, Total Score=0.162739]\n",
      "2it [00:00, 29.64it/s, Epoch=50, Val Loss=0.080487, Total Val Loss=0.080322, Val Score=0.145877, Total Val Score=0.148762]\n"
     ]
    }
   ],
   "source": [
    "loss_plot, val_loss_plot = [], []\n",
    "score_plot, val_score_plot = [], []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    print(\"epoch {}\".format(epoch))\n",
    "    \n",
    "    total_loss, total_val_loss = 0, 0\n",
    "    total_score, total_val_score = 0, 0\n",
    "    \n",
    "    tqdm_dataset = tqdm(enumerate(train_dataloader))\n",
    "    training = True\n",
    "    for batch, batch_item in tqdm_dataset:\n",
    "        batch_loss, batch_score = train_step(batch_item, epoch, batch, training, teacher_forcing)\n",
    "        total_loss += batch_loss\n",
    "        total_score += batch_score\n",
    "        \n",
    "        tqdm_dataset.set_postfix({\n",
    "            'Epoch': epoch + 1,\n",
    "            'Loss': '{:06f}'.format(batch_loss.item()),\n",
    "            'Total Loss' : '{:06f}'.format(total_loss/(batch+1)),\n",
    "            'Score': '{:06f}'.format(batch_score.item()),\n",
    "            'Total Score' : '{:06f}'.format(total_score/(batch+1)),\n",
    "        })\n",
    "    loss_plot.append(total_loss/(batch+1))\n",
    "    score_plot.append(total_score/(batch+1))\n",
    "    \n",
    "    tqdm_dataset = tqdm(enumerate(val_dataloader))\n",
    "    training = False\n",
    "    for batch, batch_item in tqdm_dataset:\n",
    "        batch_loss, batch_val_score = train_step(batch_item, epoch, batch, training, teacher_forcing)\n",
    "        total_val_loss += batch_loss\n",
    "        total_val_score += batch_val_score\n",
    "        \n",
    "        tqdm_dataset.set_postfix({\n",
    "            'Epoch': epoch + 1,\n",
    "            'Val Loss': '{:06f}'.format(batch_loss.item()),\n",
    "            'Total Val Loss' : '{:06f}'.format(total_val_loss/(batch+1)),\n",
    "            'Val Score': '{:06f}'.format(batch_val_score.item()),\n",
    "            'Total Val Score' : '{:06f}'.format(total_val_score/(batch+1)),\n",
    "        })\n",
    "    val_loss_plot.append(total_val_loss/(batch+1))\n",
    "    val_score_plot.append(total_val_score/(batch+1))\n",
    "    \n",
    "    if np.min(val_loss_plot) == val_loss_plot[-1]:\n",
    "        torch.save(model, save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_plot, label='train_loss')\n",
    "plt.plot(val_loss_plot, label='val_loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss(mae)')\n",
    "plt.title('loss_plot')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(score_plot, label='train_score')\n",
    "plt.plot(val_score_plot, label='val_score')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('score(nmae)')\n",
    "plt.title('score_plot')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = torch.load(save_path)\n",
    "test_model = test_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(encoder_input):\n",
    "    test_model.train()\n",
    "    encoder_input = encoder_input.to(device)\n",
    "    decoder_input = torch.zeros([1, future_size+1, target_n], dtype=torch.float32).to(device)\n",
    "    with torch.no_grad():\n",
    "        output = test_model(encoder_input, decoder_input, False)\n",
    "    return output.cpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "public_date_list = submission[submission['예측대상일자'].str.contains('2020')]['예측대상일자'].str.split('+').str[0].unique() \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = []\n",
    "troch_norm = torch.tensor(norm.to_numpy()[2::2])\n",
    "for date in public_date_list:\n",
    "    test_df = pd.read_csv(f'public_data/test_files/test_{date}.csv')\n",
    "    data = pd.read_csv('public_data/train.csv')\n",
    "    data = pd.concat([data, test_df]).iloc[-window_size:]\n",
    "    \n",
    "    week_day_map = {}\n",
    "    for i, d in enumerate(data['요일'].unique()):\n",
    "        week_day_map[d] = i\n",
    "    data['요일'] = data['요일'].map(week_day_map)\n",
    "    data = data.iloc[:,1:]/norm\n",
    "    \n",
    "    encoder_input = torch.tensor(data.to_numpy(), dtype=torch.float32)\n",
    "    encoder_input = encoder_input.unsqueeze(0)\n",
    "    output = predict(encoder_input)*troch_norm\n",
    "    \n",
    "    idx = submission[submission['예측대상일자'].str.contains(date)].index\n",
    "    submission.loc[idx, '배추_가격(원/kg)':] = output[0,[6,13,27]].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>예측대상일자</th>\n",
       "      <th>배추_가격(원/kg)</th>\n",
       "      <th>무_가격(원/kg)</th>\n",
       "      <th>양파_가격(원/kg)</th>\n",
       "      <th>건고추_가격(원/kg)</th>\n",
       "      <th>마늘_가격(원/kg)</th>\n",
       "      <th>대파_가격(원/kg)</th>\n",
       "      <th>얼갈이배추_가격(원/kg)</th>\n",
       "      <th>양배추_가격(원/kg)</th>\n",
       "      <th>깻잎_가격(원/kg)</th>\n",
       "      <th>...</th>\n",
       "      <th>당근_가격(원/kg)</th>\n",
       "      <th>파프리카_가격(원/kg)</th>\n",
       "      <th>새송이_가격(원/kg)</th>\n",
       "      <th>팽이버섯_가격(원/kg)</th>\n",
       "      <th>토마토_가격(원/kg)</th>\n",
       "      <th>청상추_가격(원/kg)</th>\n",
       "      <th>백다다기_가격(원/kg)</th>\n",
       "      <th>애호박_가격(원/kg)</th>\n",
       "      <th>캠벨얼리_가격(원/kg)</th>\n",
       "      <th>샤인마스캇_가격(원/kg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-09-29+1week</td>\n",
       "      <td>721.262768</td>\n",
       "      <td>1151.425524</td>\n",
       "      <td>1085.619807</td>\n",
       "      <td>22205.184001</td>\n",
       "      <td>5107.936776</td>\n",
       "      <td>1912.256668</td>\n",
       "      <td>1310.489631</td>\n",
       "      <td>1373.222821</td>\n",
       "      <td>6841.336470</td>\n",
       "      <td>...</td>\n",
       "      <td>1488.916464</td>\n",
       "      <td>4246.405673</td>\n",
       "      <td>2529.635906</td>\n",
       "      <td>1824.883870</td>\n",
       "      <td>4395.847943</td>\n",
       "      <td>4737.101472</td>\n",
       "      <td>2549.350986</td>\n",
       "      <td>2240.288625</td>\n",
       "      <td>3805.322945</td>\n",
       "      <td>7024.998069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-09-29+2week</td>\n",
       "      <td>755.218789</td>\n",
       "      <td>980.346909</td>\n",
       "      <td>1083.718538</td>\n",
       "      <td>17485.364401</td>\n",
       "      <td>5151.911671</td>\n",
       "      <td>1861.040347</td>\n",
       "      <td>1118.632704</td>\n",
       "      <td>1247.585582</td>\n",
       "      <td>5932.773471</td>\n",
       "      <td>...</td>\n",
       "      <td>1646.757871</td>\n",
       "      <td>4853.798976</td>\n",
       "      <td>2589.343786</td>\n",
       "      <td>1789.264099</td>\n",
       "      <td>4643.923950</td>\n",
       "      <td>3076.522218</td>\n",
       "      <td>2449.268632</td>\n",
       "      <td>2050.477375</td>\n",
       "      <td>3718.629479</td>\n",
       "      <td>6478.184462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-09-29+4week</td>\n",
       "      <td>869.424790</td>\n",
       "      <td>847.794456</td>\n",
       "      <td>1056.710005</td>\n",
       "      <td>18998.865627</td>\n",
       "      <td>4898.591450</td>\n",
       "      <td>1777.475279</td>\n",
       "      <td>988.617877</td>\n",
       "      <td>1269.309343</td>\n",
       "      <td>5833.566536</td>\n",
       "      <td>...</td>\n",
       "      <td>1800.350212</td>\n",
       "      <td>5274.428100</td>\n",
       "      <td>2599.436522</td>\n",
       "      <td>1671.288574</td>\n",
       "      <td>4604.940678</td>\n",
       "      <td>1870.010357</td>\n",
       "      <td>2392.472383</td>\n",
       "      <td>1841.738105</td>\n",
       "      <td>3621.167690</td>\n",
       "      <td>4847.221076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-09-30+1week</td>\n",
       "      <td>670.602098</td>\n",
       "      <td>1268.034153</td>\n",
       "      <td>1153.078079</td>\n",
       "      <td>18816.459280</td>\n",
       "      <td>4885.435841</td>\n",
       "      <td>2130.905637</td>\n",
       "      <td>1533.638438</td>\n",
       "      <td>1442.280898</td>\n",
       "      <td>7949.867856</td>\n",
       "      <td>...</td>\n",
       "      <td>1746.656634</td>\n",
       "      <td>5155.423977</td>\n",
       "      <td>2595.144987</td>\n",
       "      <td>2061.586276</td>\n",
       "      <td>4624.939051</td>\n",
       "      <td>5816.106336</td>\n",
       "      <td>2757.735536</td>\n",
       "      <td>2441.836690</td>\n",
       "      <td>4038.110003</td>\n",
       "      <td>6773.374081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-09-30+2week</td>\n",
       "      <td>675.509945</td>\n",
       "      <td>1102.542191</td>\n",
       "      <td>1151.970625</td>\n",
       "      <td>19224.502283</td>\n",
       "      <td>5045.595035</td>\n",
       "      <td>2035.378208</td>\n",
       "      <td>1337.705883</td>\n",
       "      <td>1340.580595</td>\n",
       "      <td>7789.935670</td>\n",
       "      <td>...</td>\n",
       "      <td>1823.007166</td>\n",
       "      <td>6182.803075</td>\n",
       "      <td>2679.019928</td>\n",
       "      <td>2059.784717</td>\n",
       "      <td>4867.978347</td>\n",
       "      <td>4098.087689</td>\n",
       "      <td>2674.687355</td>\n",
       "      <td>2415.411840</td>\n",
       "      <td>3879.119828</td>\n",
       "      <td>5403.242707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>2021-11-03+2week</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>2021-11-03+4week</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>2021-11-04+1week</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>2021-11-04+2week</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>2021-11-04+4week</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>228 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               예측대상일자  배추_가격(원/kg)   무_가격(원/kg)  양파_가격(원/kg)  건고추_가격(원/kg)  \\\n",
       "0    2020-09-29+1week   721.262768  1151.425524  1085.619807  22205.184001   \n",
       "1    2020-09-29+2week   755.218789   980.346909  1083.718538  17485.364401   \n",
       "2    2020-09-29+4week   869.424790   847.794456  1056.710005  18998.865627   \n",
       "3    2020-09-30+1week   670.602098  1268.034153  1153.078079  18816.459280   \n",
       "4    2020-09-30+2week   675.509945  1102.542191  1151.970625  19224.502283   \n",
       "..                ...          ...          ...          ...           ...   \n",
       "223  2021-11-03+2week     0.000000     0.000000     0.000000      0.000000   \n",
       "224  2021-11-03+4week     0.000000     0.000000     0.000000      0.000000   \n",
       "225  2021-11-04+1week     0.000000     0.000000     0.000000      0.000000   \n",
       "226  2021-11-04+2week     0.000000     0.000000     0.000000      0.000000   \n",
       "227  2021-11-04+4week     0.000000     0.000000     0.000000      0.000000   \n",
       "\n",
       "     마늘_가격(원/kg)  대파_가격(원/kg)  얼갈이배추_가격(원/kg)  양배추_가격(원/kg)  깻잎_가격(원/kg)  ...  \\\n",
       "0    5107.936776  1912.256668     1310.489631   1373.222821  6841.336470  ...   \n",
       "1    5151.911671  1861.040347     1118.632704   1247.585582  5932.773471  ...   \n",
       "2    4898.591450  1777.475279      988.617877   1269.309343  5833.566536  ...   \n",
       "3    4885.435841  2130.905637     1533.638438   1442.280898  7949.867856  ...   \n",
       "4    5045.595035  2035.378208     1337.705883   1340.580595  7789.935670  ...   \n",
       "..           ...          ...             ...           ...          ...  ...   \n",
       "223     0.000000     0.000000        0.000000      0.000000     0.000000  ...   \n",
       "224     0.000000     0.000000        0.000000      0.000000     0.000000  ...   \n",
       "225     0.000000     0.000000        0.000000      0.000000     0.000000  ...   \n",
       "226     0.000000     0.000000        0.000000      0.000000     0.000000  ...   \n",
       "227     0.000000     0.000000        0.000000      0.000000     0.000000  ...   \n",
       "\n",
       "     당근_가격(원/kg)  파프리카_가격(원/kg)  새송이_가격(원/kg)  팽이버섯_가격(원/kg)  토마토_가격(원/kg)  \\\n",
       "0    1488.916464    4246.405673   2529.635906    1824.883870   4395.847943   \n",
       "1    1646.757871    4853.798976   2589.343786    1789.264099   4643.923950   \n",
       "2    1800.350212    5274.428100   2599.436522    1671.288574   4604.940678   \n",
       "3    1746.656634    5155.423977   2595.144987    2061.586276   4624.939051   \n",
       "4    1823.007166    6182.803075   2679.019928    2059.784717   4867.978347   \n",
       "..           ...            ...           ...            ...           ...   \n",
       "223     0.000000       0.000000      0.000000       0.000000      0.000000   \n",
       "224     0.000000       0.000000      0.000000       0.000000      0.000000   \n",
       "225     0.000000       0.000000      0.000000       0.000000      0.000000   \n",
       "226     0.000000       0.000000      0.000000       0.000000      0.000000   \n",
       "227     0.000000       0.000000      0.000000       0.000000      0.000000   \n",
       "\n",
       "     청상추_가격(원/kg)  백다다기_가격(원/kg)  애호박_가격(원/kg)  캠벨얼리_가격(원/kg)  샤인마스캇_가격(원/kg)  \n",
       "0     4737.101472    2549.350986   2240.288625    3805.322945     7024.998069  \n",
       "1     3076.522218    2449.268632   2050.477375    3718.629479     6478.184462  \n",
       "2     1870.010357    2392.472383   1841.738105    3621.167690     4847.221076  \n",
       "3     5816.106336    2757.735536   2441.836690    4038.110003     6773.374081  \n",
       "4     4098.087689    2674.687355   2415.411840    3879.119828     5403.242707  \n",
       "..            ...            ...           ...            ...             ...  \n",
       "223      0.000000       0.000000      0.000000       0.000000        0.000000  \n",
       "224      0.000000       0.000000      0.000000       0.000000        0.000000  \n",
       "225      0.000000       0.000000      0.000000       0.000000        0.000000  \n",
       "226      0.000000       0.000000      0.000000       0.000000        0.000000  \n",
       "227      0.000000       0.000000      0.000000       0.000000        0.000000  \n",
       "\n",
       "[228 rows x 22 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('seq2seq_baseline.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
